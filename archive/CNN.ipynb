{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point \n",
    "my_model= models.Sequential()\n",
    "\n",
    "# Add first convolutional block\n",
    "my_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', \n",
    "                    input_shape=(178,218,3)))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# second block\n",
    "my_model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# third block\n",
    "my_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# fourth block\n",
    "my_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global average pooling\n",
    "my_model.add(GlobalAveragePooling2D())\n",
    "# fully connected layer\n",
    "my_model.add(Dense(64, activation='relu'))\n",
    "my_model.add(BatchNormalization())\n",
    "# make predictions\n",
    "my_model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 178, 218, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 89, 109, 16)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,922\n",
      "Trainable params: 1,794\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "my_model.summary()\n",
    "\n",
    "# use early stopping to optimally terminate training through callbacks\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# save best model automatically\n",
    "mc= ModelCheckpoint(r'C:\\Users\\User\\Desktop\\4th_year_AMLS\\zceecyt-AMLSassignment19_20-16053203\\dataset\\celeba', monitor='val_loss', \n",
    "                    mode='min', verbose=1, save_best_only=True)\n",
    "cb_list=[es,mc]\n",
    "\n",
    "\n",
    "# compile model \n",
    "my_model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# set up data generator\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# get batches of training images from the directory\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        r'C:\\Users\\User\\Desktop\\4th_year_AMLS\\zceecyt-AMLSassignment19_20-16053203\\dataset\\celeba',\n",
    "        target_size=(178, 218),\n",
    "        batch_size=12,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get batches of validation images from the directory\n",
    "validation_generator = data_generator.flow_from_directory(r'C:\\Users\\User\\Desktop\\4th_year_AMLS\\zceecyt-AMLSassignment19_20-16053203\\dataset\\celeba',  \n",
    "        target_size=(178, 218),\n",
    "        batch_size=12,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = my_model.fit_generator(\n",
    "#         train_generator,\n",
    "#         epochs=30,\n",
    "#         steps_per_epoch=2667,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=667, callbacks=cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot training and validation accuracy\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.ylim([.5,1.1])\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.savefig(\"Custom_Keras_ODSC.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Testing ################################\n",
    "\n",
    "# # load a saved model\n",
    "# from keras.models import load_model\n",
    "# import os\n",
    "# os.chdir('yourdirectory')\n",
    "# saved_model = load_model('Custom_Keras_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate data for test set of images\n",
    "# test_generator = data_generator.flow_from_directory(\n",
    "#         'C:/Users/w10007346/Pictures/Celeb_sets/test',\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=1,\n",
    "#         class_mode='categorical',\n",
    "#         shuffle=False)\n",
    "\n",
    "# # obtain predicted activation values for the last dense layer\n",
    "# import numpy as np\n",
    "# test_generator.reset()\n",
    "# pred=saved_model.predict_generator(test_generator, verbose=1, steps=1000)\n",
    "# # determine the maximum activation value for each sample\n",
    "# predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "# # label each predicted value to correct gender\n",
    "# labels = (test_generator.class_indices)\n",
    "# labels = dict((v,k) for k,v in labels.items())\n",
    "# predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# # format file names to simply male or female\n",
    "# filenames=test_generator.filenames\n",
    "# filenz=[0]\n",
    "# for i in range(0,len(filenames)):\n",
    "#     filenz.append(filenames[i].split('\\\\')[0])\n",
    "# filenz=filenz[1:]\n",
    "\n",
    "# # determine the test set accuracy\n",
    "# match=[]\n",
    "# for i in range(0,len(filenames)):\n",
    "#     match.append(filenz[i]==predictions[i])\n",
    "# match.count(True)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "#                                    validation_split=0.15\n",
    "# )\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_path = MAIN_DIR + '/CancerTrain'\n",
    "# valid_path = MAIN_DIR + '/CancerTrain'\n",
    "\n",
    "\n",
    "\n",
    "# train_generator = train_datagen.flow_from_dataframe(\n",
    "#                 dataframe = train_labels,\n",
    "#                 directory=train_path,\n",
    "#                 x_col = 'id',\n",
    "#                 y_col = 'label',\n",
    "#                 has_ext=False,\n",
    "#                 subset='training',\n",
    "#                 target_size=(96, 96),\n",
    "#                 batch_size=64,\n",
    "#                 class_mode='binary'\n",
    "#                 )\n",
    "\n",
    "# validation_generator = train_datagen.flow_from_dataframe(\n",
    "#                 dataframe=df,\n",
    "#                 directory=valid_path,\n",
    "#                 x_col = 'id',\n",
    "#                 y_col = 'label',\n",
    "#                 has_ext=False,\n",
    "#                 subset='validation', # This is the trick to properly separate train and validation dataset\n",
    "#                 target_size=(96, 96),\n",
    "#                 batch_size=64,\n",
    "#                 shuffle=False,\n",
    "#                 class_mode='binary'\n",
    "#                 )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
