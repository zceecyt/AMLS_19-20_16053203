{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# img = cv2.imread('xfiles4.jpg')\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "\n",
    "# for (x,y,w,h) in faces:\n",
    "#     cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#     roi_gray = gray[y:y+h, x:x+w]\n",
    "#     roi_color = img[y:y+h, x:x+w]\n",
    "#     eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#     for (ex,ey,ew,eh) in eyes:\n",
    "#         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from shutil import copyfile\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# rootdir = 'E:Files/user_data'\n",
    "# output_path = 'E:/Files/Test_Folder/'\n",
    "\n",
    "\n",
    "# def path_source_img(_id, record_id):\n",
    "#     global rootdir\n",
    "#     return os.path.join(rootdir, str(_id), '{}.jpg'.format(record_id))\n",
    "\n",
    "\n",
    "# def path_dest_img(_type, _id, record_id):\n",
    "#     global output_path\n",
    "#     return os.path.join(output_path, _type,\n",
    "#                         '{}_{}_{}.jpg'.format(_type, _id, record_id))\n",
    "\n",
    "\n",
    "# df = pd.read_csv('file.csv')\n",
    "\n",
    "# if not os.path.exists(output_path):\n",
    "#     os.makedirs(os.path.dirname(output_path))\n",
    "\n",
    "# for _type in df['Type'].unique():\n",
    "#     imgs = df[df['Type'] == _type]\n",
    "#     for index, img in imgs.iterrows():\n",
    "#         from_img = path_source_img(img['id'], img['record_id'])\n",
    "#         to_img = path_dest_img(_type, img['id'], img['record_id'])\n",
    "#         print(from_img, '->', to_img)\n",
    "#         if not os.path.exists(output_path):\n",
    "#             os.makedirs(os.path.dirname(to_img))\n",
    "#         copyfile(from_img, to_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = 'sep_img'\n",
    "# f = 'female'\n",
    "# m = 'male'\n",
    "\n",
    "# os.makedirs(folder +'/train' + f, exist_ok=True)\n",
    "# os.makedirs(folder +'/train' + m, exist_ok=True)\n",
    "# os.makedirs(folder +'/val' + f, exist_ok=True)\n",
    "# os.makedirs(folder +'/val' + m, exist_ok=True)\n",
    "# os.makedirs(folder +'/test' + f, exist_ok=True)\n",
    "# os.makedirs(folder +'/test' + m, exist_ok=True)\n",
    "\n",
    "# current = f\n",
    "# src = \"sep_img\"+current\n",
    "\n",
    "# src_dir = (\"labels.csv\")\n",
    "# df_male.loc[:,'gender'] = df_male['gender']\n",
    "# df_female.loc[:, 'gender'] = df_female['gender'].apply(lambda x : 0)\n",
    "\n",
    "# if not os.path.exists(output_path):\n",
    "#     os.makedirs(os.path.dirname(output_path))\n",
    "\n",
    "# for _type in df['Type'].unique():\n",
    "#     imgs = df[df['Type'] == _type]\n",
    "#     for index, img in imgs.iterrows():\n",
    "#         from_img = path_source_img(img['id'], img['record_id'])\n",
    "#         to_img = path_dest_img(_type, img['id'], img['record_id'])\n",
    "#         print(from_img, '->', to_img)\n",
    "#         if not os.path.exists(output_path):\n",
    "#             os.makedirs(os.path.dirname(to_img))\n",
    "#         copyfile(from_img, to_img)\n",
    "# if  df[df['gender'] == 1]:\n",
    "#     dst_dir = \"sep_img\\trainfemale\"\n",
    "# else:\n",
    "#     dst_dir = \"sep_img\\trainmale\"\n",
    "\n",
    "\n",
    "# allFiles = os.listdir(r\"C:\\Users\\User\\Desktop\\4th_year_AMLS\\zceecyt-AMLSassignment19_20-16053203\\dataset\\celeba\\img\")\n",
    "# np.random.shuffle(allFiles)\n",
    "# train_Files, val_Files, test_Files = np.split(np.array(allFiles),[int(len(allFiles)*0.7), int(len(allFiles)*0.9)])\n",
    "\n",
    "\n",
    "# train_Files = [src+'/'+ name for name in train_Files.tolist()]\n",
    "# val_Files = [src+'/' + name for name in val_Files.tolist()]\n",
    "# test_Files = [src+'/' + name for name in test_Files.tolist()]\n",
    "\n",
    "# print('Total images: ', len(allFiles))\n",
    "# print('Training: ', len(train_Files))\n",
    "# print('Validation: ', len(val_Files))\n",
    "# print('Testing: ', len(test_Files))\n",
    "\n",
    "# for name in train_Files:\n",
    "#     shutil.copy(name, \"sep_img/train\"+current)\n",
    "\n",
    "# for name in val_Files:\n",
    "#     shutil.copy(name, \"sep_img/val\"+current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r'C:\\Users\\User\\Desktop\\4th_year_AMLS\\zceecyt-AMLSassignment19_20-16053203\\dataset\\celeba')\n",
    "# cwd = os.getcwd()\n",
    "# # print(\"Current working directory is:\", cwd)\n",
    "# # df = pd.read_csv('labels.csv')\n",
    "# # df = open('../../dataset/celeba/labels.csv')\n",
    "# df = open('labels.csv')\n",
    "# reader = csv.reader(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('labels.csv', sep = '\\t')\n",
    "# df = df.drop(columns = [df.columns[0]]).drop(columns = [df.columns[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_female = df[df['gender'] == -1]\n",
    "# df_female.loc[:, 'gender'] = df_female['gender'].apply(lambda x : 0)\n",
    "# df_female\n",
    "# df_male = df[df['gender'] == 1]\n",
    "# df_male.loc[:,'gender'] = df_male['gender']\n",
    "# df_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'kernel':('linear', 'rbf', 'poly'), 'C':[0.1, 1, 10], 'gamma':[0.0001, 0.001, 0.01], 'degree':[1, 2, 3, 4]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters)\n",
    "# clf.fit(te_X, te_Y)\n",
    "# GridSearchCV(estimator=SVC(),\n",
    "#              param_grid={'C':[0.1, 1, 10], 'gamma':[0.0001, 0.001, 0.01], 'degree':[1, 2, 3, 4], 'kernel': ('linear', 'rbf', 'poly')})\n",
    "# sorted(clf.cv_results_.keys())\n",
    "# ['mean_fit_time', 'mean_score_time', 'mean_test_score',\n",
    "#  'param_C', 'param_kernel', 'param_gamma', 'param_degree','params',\n",
    "#  'rank_test_score', 'split0_test_score',\n",
    "#  'split2_test_score', \n",
    "#  'std_fit_time', 'std_score_time', 'std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles_title = [(\"Confusion matrix, without normalization\", None),\n",
    "#          (\"Normalized confusion matrix\", 'true')]\n",
    "# for title, normalize in titles_title:\n",
    "#     disp = plot_confusion_matrix (poly_svc, te_X, te_Y,\n",
    "# #                                  display_labels = Y,\n",
    "# #                                   display_labels\n",
    "#                                  cmap=plt.cm.Blues,\n",
    "#                                  normalize=normalize)\n",
    "#     disp.ax_.set_title(title)\n",
    "\n",
    "#     print (title)\n",
    "#     print(disp.confusion_matrix)\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('my_SVM.pkl','wb') as f:\n",
    "#     pickle.dump(optimised_poly, f)\n",
    "# with open('my_SVM.pkl','rb') as f:\n",
    "#     optimised_poly = pickle.load(f)\n",
    "# categories = [\"0\",\"1\"]\n",
    "# image = \"../../dataset_test_AMLS_19-20/celeba_test/img\"\n",
    "# newpred = optimised_poly([image])\n",
    "# newpred = list(newpred[0])\n",
    "# print(categories[newpred.index(max(newpred))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # Plot n_samples vs fit_times\n",
    "#     axes[1].grid()\n",
    "#     axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "#     axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "#                          fit_times_mean + fit_times_std, alpha=0.1)\n",
    "#     axes[1].set_xlabel(\"Training examples\")\n",
    "#     axes[1].set_ylabel(\"fit_times\")\n",
    "#     axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "#     # Plot fit_time vs score\n",
    "#     axes[2].grid()\n",
    "#     axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "#     axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "#                          test_scores_mean + test_scores_std, alpha=0.1)\n",
    "#     axes[2].set_xlabel(\"fit_times\")\n",
    "#     axes[2].set_ylabel(\"Score\")\n",
    "#     axes[2].set_title(\"Performance of the model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdscale = preprocessing.StandardScaler().fit(tr_X)\n",
    "# tr_X = stdscale.transform(tr_X)\n",
    "# te_X = stdscale.transform(te_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_list = []\n",
    "\n",
    "# lin_svc = svm.SVC(kernel='linear', C=C).fit(tr_X, tr_Y)\n",
    "# # print(C, \"Linear:\", lin_svc.score(te_X, te_Y))\n",
    "\n",
    "# rbf_svc = svm.SVC(kernel='rbf', gamma=gamma, C=C).fit(tr_X, tr_Y)\n",
    "# # print( C, gamma, \"Rbf:\", rbf_svc.score(te_X, te_Y))\n",
    "\n",
    "# poly_svc = svm.SVC(kernel='poly', degree=degree, C=C).fit(tr_X, tr_Y)\n",
    "# # print( C, degree, \"Poly\", poly_svc.score(te_X, te_Y))\n",
    "\n",
    "# svc_list.append({\n",
    "#     'lin_svc': lin_svc,\n",
    "#     'rbf_svc': rbf_svc,\n",
    "#     'poly_svc': poly_svc,\n",
    "#     'C': C,\n",
    "#     'gamma': gamma,\n",
    "#     'degree': degree\n",
    "# })\n",
    "\n",
    "# #define model and performance measure\n",
    "# svc_list=svc(probability=True, random_state=1)\n",
    "# auc=make_scorer(roc_auc_score)\n",
    "\n",
    "# #random search for 20 combinations of parameters\n",
    "# rand_list = {\"C\":stats.uniform(2,10),\n",
    "#             \"gamma\":stats.uniform(0.1,1),\n",
    "#             \"degree\":stats.uniform(1,3)}\n",
    "\n",
    "# rand_search = RandomizedSearchCV(svc_list, param_distributions = rand_list, n_iter=20, n_jobs=4, cv=3, random_state=2017, scoring=auc)\n",
    "# rand_search.fit(tr_X, tr_Y)\n",
    "# rand_search.cv_results_\n",
    "\n",
    "# print(rand_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
