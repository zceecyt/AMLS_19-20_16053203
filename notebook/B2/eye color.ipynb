{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import adam\n",
    "from keras import models\n",
    "import cv2\n",
    "import dlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time \n",
    "import progressbar\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eye_color</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3</td>\n",
       "      <td>9995.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>9996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>9997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>9998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>9999.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eye_color file_name\n",
       "0            1     0.png\n",
       "1            2     1.png\n",
       "2            2     2.png\n",
       "3            2     3.png\n",
       "4            0     4.png\n",
       "...        ...       ...\n",
       "9995         3  9995.png\n",
       "9996         0  9996.png\n",
       "9997         1  9997.png\n",
       "9998         0  9998.png\n",
       "9999         2  9999.png\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../dataset/cartoon_set/labels.csv', sep = '\\t')\n",
    "df = df.drop(columns = [df.columns[0]]).drop(columns = [df.columns[2]])\n",
    "df['eye_color'] = df['eye_color'].apply(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ('../../dataset/cartoon_set/img')\n",
    "# training, testing = train_test_split(df, random_state=0)\n",
    "for x in [0.6,0.65,0.7,0.75,0.8]:\n",
    "    for y in [0.8,0.8,0.85,0.85,0.9]: #help\n",
    "        training, validating, testing = np.split(df.sample(frac=1), [int(x*len(df)), int(y*len(df))]) #splitting at n-array\n",
    "# print(training, validating, testing)\n",
    "#         print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Preparation: \n",
      "Found 8000 validated image filenames belonging to 5 classes.\n",
      "\n",
      "Validation Dataset Preparation: \n",
      "Found 1000 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# set up data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "#     validation_split = 0.25,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True   \n",
    ")\n",
    "\n",
    "# # get batches of training images from the df\n",
    "# train_generator = data_generator.flow_from_dataframe(\n",
    "#         dataframe=train_set,\n",
    "#         x_col=\"file_name\",\n",
    "#         y_col=\"face_shape\",\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=12,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# validate_generator = data_generator.flow_from_dataframe(\n",
    "#         dataframe=train_set,\n",
    "#         x_col=\"file_name\",\n",
    "#         y_col=\"face_shape\",\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=12,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# Get batches of training dataset from the dataframe\n",
    "print(\"Training Dataset Preparation: \")\n",
    "train_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = training, directory = img ,\n",
    "        x_col = \"file_name\", y_col = \"eye_color\",\n",
    "        class_mode = 'categorical', target_size = (30,30),\n",
    "        batch_size = 32, subset = 'training') \n",
    "   \n",
    "# Get batches of validation dataset from the dataframe\n",
    "print(\"\\nValidation Dataset Preparation: \")\n",
    "validation_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = validating, directory = img ,\n",
    "        x_col = \"file_name\", y_col = \"eye_color\",\n",
    "        class_mode = 'categorical', target_size = (30,30),\n",
    "        batch_size = 32, subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 100,005\n",
      "Trainable params: 100,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# starting point \n",
    "my_model= models.Sequential()\n",
    "\n",
    "# Add first convolutional block\n",
    "my_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', \n",
    "                    input_shape=(30,30,3))) #height, width, depth\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# second block\n",
    "my_model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) #Convolution: filters, kernel_size that specifies the height and width of the 2D convolution window, p padding layers so dimensions of input = output\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# third block\n",
    "my_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# fourth block\n",
    "my_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# global average pooling\n",
    "#my_model.add(GlobalAveragePooling2D())\n",
    "# fully connected layer\n",
    "#my_model.add(Dense(64, activation='relu'))\n",
    "#my_model.add(BatchNormalization())\n",
    "# make predictions\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Dense(5, activation='softmax'))\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use early stopping to optimally terminate training through callbacks\n",
    "\n",
    "# es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# # save best model automatically\n",
    "# mc= ModelCheckpoint('/../../dataset/cartoon_set', monitor='val_loss', \n",
    "#                     mode='min', verbose=1, save_best_only=True)\n",
    "# cb_list=[es,mc]\n",
    "\n",
    "\n",
    "# compile model \n",
    "my_model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 61s 246ms/step - loss: 1.6104 - accuracy: 0.2111 - val_loss: 1.5956 - val_accuracy: 0.1855\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 77s 309ms/step - loss: 1.5007 - accuracy: 0.2935 - val_loss: 1.5039 - val_accuracy: 0.3833\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 78s 310ms/step - loss: 1.3362 - accuracy: 0.4022 - val_loss: 1.2483 - val_accuracy: 0.4246\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 77s 308ms/step - loss: 1.2163 - accuracy: 0.4509 - val_loss: 1.1480 - val_accuracy: 0.4669\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 76s 305ms/step - loss: 1.1200 - accuracy: 0.4896 - val_loss: 1.2139 - val_accuracy: 0.5124\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 76s 303ms/step - loss: 1.0295 - accuracy: 0.5356 - val_loss: 0.6900 - val_accuracy: 0.5341\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 76s 305ms/step - loss: 0.9524 - accuracy: 0.5789 - val_loss: 0.8659 - val_accuracy: 0.6012\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 70s 281ms/step - loss: 0.8437 - accuracy: 0.6417 - val_loss: 0.5303 - val_accuracy: 0.6260\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 68s 273ms/step - loss: 0.7568 - accuracy: 0.6760 - val_loss: 0.5991 - val_accuracy: 0.6777\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 68s 271ms/step - loss: 0.6828 - accuracy: 0.7014 - val_loss: 1.0278 - val_accuracy: 0.7004\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.6104 - accuracy: 0.7430 - val_loss: 0.7111 - val_accuracy: 0.7169\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.5877 - accuracy: 0.7437 - val_loss: 0.5175 - val_accuracy: 0.7273\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 0.5503 - accuracy: 0.7646 - val_loss: 0.7393 - val_accuracy: 0.7407\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 68s 270ms/step - loss: 0.5213 - accuracy: 0.7764 - val_loss: 0.8763 - val_accuracy: 0.7593\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.5060 - accuracy: 0.7821 - val_loss: 0.5526 - val_accuracy: 0.7552\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 0.4788 - accuracy: 0.7893 - val_loss: 0.5382 - val_accuracy: 0.7686\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.4685 - accuracy: 0.8005 - val_loss: 0.5106 - val_accuracy: 0.7541\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 0.4530 - accuracy: 0.8045 - val_loss: 0.5144 - val_accuracy: 0.7521\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.4695 - accuracy: 0.8008 - val_loss: 0.7195 - val_accuracy: 0.7583\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 75s 301ms/step - loss: 0.4484 - accuracy: 0.8076 - val_loss: 0.5158 - val_accuracy: 0.7459\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 74s 297ms/step - loss: 0.4332 - accuracy: 0.8166 - val_loss: 0.6057 - val_accuracy: 0.7717\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 74s 298ms/step - loss: 0.4155 - accuracy: 0.8225 - val_loss: 0.7394 - val_accuracy: 0.7707\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 76s 302ms/step - loss: 0.4143 - accuracy: 0.8242 - val_loss: 0.7411 - val_accuracy: 0.7769\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 73s 292ms/step - loss: 0.4224 - accuracy: 0.8191 - val_loss: 0.6846 - val_accuracy: 0.7593\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 74s 294ms/step - loss: 0.4019 - accuracy: 0.8292 - val_loss: 0.2512 - val_accuracy: 0.7717\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "history = my_model.fit_generator(\n",
    "                                train_generator,\n",
    "                                epochs=25,\n",
    "                                steps_per_epoch=train_generator.samples // batch_size,\n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=validation_generator.samples // batch_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1789.5763294696808 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
