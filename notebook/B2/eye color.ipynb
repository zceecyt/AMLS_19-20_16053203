{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import adam\n",
    "from keras import models\n",
    "import cv2\n",
    "import dlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time \n",
    "import progressbar\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eye_color</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3</td>\n",
       "      <td>9995.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>9996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>9997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>9998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>9999.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eye_color file_name\n",
       "0            1     0.png\n",
       "1            2     1.png\n",
       "2            2     2.png\n",
       "3            2     3.png\n",
       "4            0     4.png\n",
       "...        ...       ...\n",
       "9995         3  9995.png\n",
       "9996         0  9996.png\n",
       "9997         1  9997.png\n",
       "9998         0  9998.png\n",
       "9999         2  9999.png\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../dataset/cartoon_set/labels.csv', sep = '\\t')\n",
    "df = df.drop(columns = [df.columns[0]]).drop(columns = [df.columns[2]])\n",
    "df['eye_color'] = df['eye_color'].apply(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ('../../dataset/cartoon_set/img')\n",
    "# training, testing = train_test_split(df, random_state=0)\n",
    "for x in [0.6, 0.65, 0.7, 0.75, 0.8]:\n",
    "    for y in [0.8, 0.8, 0.85, 0.85, 0.9]:\n",
    "        training, validating, testing = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))]) #splitting at n-array\n",
    "# print(training, validating, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Preparation: \n",
      "Found 6000 validated image filenames belonging to 5 classes.\n",
      "\n",
      "Validation Dataset Preparation: \n",
      "Found 2000 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# set up data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "#     validation_split = 0.25,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True   \n",
    ")\n",
    "\n",
    "# # get batches of training images from the df\n",
    "# train_generator = data_generator.flow_from_dataframe(\n",
    "#         dataframe=train_set,\n",
    "#         x_col=\"file_name\",\n",
    "#         y_col=\"face_shape\",\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=12,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# validate_generator = data_generator.flow_from_dataframe(\n",
    "#         dataframe=train_set,\n",
    "#         x_col=\"file_name\",\n",
    "#         y_col=\"face_shape\",\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=12,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# Get batches of training dataset from the dataframe\n",
    "print(\"Training Dataset Preparation: \")\n",
    "train_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = training, directory = img ,\n",
    "        x_col = \"file_name\", y_col = \"eye_color\",\n",
    "        class_mode = 'categorical', target_size = (30,30),\n",
    "        batch_size = 32, subset = 'training') \n",
    "   \n",
    "# Get batches of validation dataset from the dataframe\n",
    "print(\"\\nValidation Dataset Preparation: \")\n",
    "validation_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = validating, directory = img ,\n",
    "        x_col = \"file_name\", y_col = \"eye_color\",\n",
    "        class_mode = 'categorical', target_size = (30,30),\n",
    "        batch_size = 32, subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 100,005\n",
      "Trainable params: 100,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# starting point \n",
    "my_model= models.Sequential()\n",
    "\n",
    "# Add first convolutional block\n",
    "my_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', \n",
    "                    input_shape=(30,30,3))) #height, width, depth\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# second block\n",
    "my_model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) #Convolution: filters, kernel_size that specifies the height and width of the 2D convolution window, p padding layers so dimensions of input = output\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# third block\n",
    "my_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# fourth block\n",
    "my_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# global average pooling\n",
    "#my_model.add(GlobalAveragePooling2D())\n",
    "# fully connected layer\n",
    "#my_model.add(Dense(64, activation='relu'))\n",
    "#my_model.add(BatchNormalization())\n",
    "# make predictions\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Dense(5, activation='softmax'))\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use early stopping to optimally terminate training through callbacks\n",
    "\n",
    "# es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# # save best model automatically\n",
    "# mc= ModelCheckpoint('/../../dataset/cartoon_set', monitor='val_loss', \n",
    "#                     mode='min', verbose=1, save_best_only=True)\n",
    "# cb_list=[es,mc]\n",
    "\n",
    "\n",
    "# compile model \n",
    "my_model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "187/187 [==============================] - 89s 476ms/step - loss: 1.6116 - accuracy: 0.1976 - val_loss: 1.6132 - val_accuracy: 0.2006\n",
      "Epoch 2/25\n",
      "187/187 [==============================] - 68s 366ms/step - loss: 1.6099 - accuracy: 0.2016 - val_loss: 1.6092 - val_accuracy: 0.2114\n",
      "Epoch 3/25\n",
      "187/187 [==============================] - 67s 358ms/step - loss: 1.6098 - accuracy: 0.1952 - val_loss: 1.6093 - val_accuracy: 0.1951\n",
      "Epoch 4/25\n",
      "187/187 [==============================] - 66s 355ms/step - loss: 1.6099 - accuracy: 0.2036 - val_loss: 1.6087 - val_accuracy: 0.1956\n",
      "Epoch 5/25\n",
      "187/187 [==============================] - 67s 361ms/step - loss: 1.6096 - accuracy: 0.2012 - val_loss: 1.6100 - val_accuracy: 0.1992\n",
      "Epoch 6/25\n",
      "187/187 [==============================] - 67s 357ms/step - loss: 1.6096 - accuracy: 0.1994 - val_loss: 1.6046 - val_accuracy: 0.1992\n",
      "Epoch 7/25\n",
      "187/187 [==============================] - 65s 346ms/step - loss: 1.5767 - accuracy: 0.2394 - val_loss: 1.4261 - val_accuracy: 0.3155\n",
      "Epoch 8/25\n",
      "187/187 [==============================] - 64s 343ms/step - loss: 1.4044 - accuracy: 0.3613 - val_loss: 1.4288 - val_accuracy: 0.3867\n",
      "Epoch 9/25\n",
      "187/187 [==============================] - 64s 342ms/step - loss: 1.3239 - accuracy: 0.4092 - val_loss: 1.0608 - val_accuracy: 0.4426\n",
      "Epoch 10/25\n",
      "187/187 [==============================] - 65s 348ms/step - loss: 1.2332 - accuracy: 0.4514 - val_loss: 1.2953 - val_accuracy: 0.4873\n",
      "Epoch 11/25\n",
      "187/187 [==============================] - 65s 346ms/step - loss: 1.1626 - accuracy: 0.4851 - val_loss: 1.0725 - val_accuracy: 0.4939\n",
      "Epoch 12/25\n",
      "187/187 [==============================] - 64s 342ms/step - loss: 1.1084 - accuracy: 0.5064 - val_loss: 1.2082 - val_accuracy: 0.5274\n",
      "Epoch 13/25\n",
      "187/187 [==============================] - 63s 338ms/step - loss: 1.0497 - accuracy: 0.5382 - val_loss: 1.2845 - val_accuracy: 0.5320\n",
      "Epoch 14/25\n",
      "187/187 [==============================] - 63s 338ms/step - loss: 1.0140 - accuracy: 0.5449 - val_loss: 1.0638 - val_accuracy: 0.5371\n",
      "Epoch 15/25\n",
      "187/187 [==============================] - 66s 352ms/step - loss: 0.9643 - accuracy: 0.5675 - val_loss: 1.0252 - val_accuracy: 0.5422\n",
      "Epoch 16/25\n",
      "187/187 [==============================] - 65s 350ms/step - loss: 0.9262 - accuracy: 0.5865 - val_loss: 1.1240 - val_accuracy: 0.5600\n",
      "Epoch 17/25\n",
      "187/187 [==============================] - 64s 341ms/step - loss: 0.8765 - accuracy: 0.6074 - val_loss: 0.9596 - val_accuracy: 0.5783\n",
      "Epoch 18/25\n",
      "187/187 [==============================] - 64s 341ms/step - loss: 0.8326 - accuracy: 0.6356 - val_loss: 0.7903 - val_accuracy: 0.5940\n",
      "Epoch 19/25\n",
      "187/187 [==============================] - 67s 358ms/step - loss: 0.7778 - accuracy: 0.6568 - val_loss: 0.8387 - val_accuracy: 0.6657\n",
      "Epoch 20/25\n",
      "187/187 [==============================] - 67s 359ms/step - loss: 0.7106 - accuracy: 0.7007 - val_loss: 0.7450 - val_accuracy: 0.6804\n",
      "Epoch 21/25\n",
      " 48/187 [======>.......................] - ETA: 33s - loss: 0.6434 - accuracy: 0.7272"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "history = my_model.fit_generator(\n",
    "                                train_generator,\n",
    "                                epochs=25,\n",
    "                                steps_per_epoch=train_generator.samples // batch_size,\n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=validation_generator.samples // batch_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
