{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import progressbar\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import dlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data file\n",
    "# data = load_iris()\n",
    "# df=pd.DataFrame(data.data,columns=data.feature_names)\n",
    "# print(df.head())\n",
    "\n",
    "# Drop rest of the features and extract the target values\n",
    "# Y = data.target\n",
    "# X = data.data[:, :2]\n",
    "\n",
    "# Shuffle and split the data into training and test set\n",
    "# X, Y = shuffle(X,Y)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def SVM(x_train,y_train, x_test):\n",
    "#     #model = ...\n",
    "#     model = SVC(kernel = 'linear')\n",
    "#     model.fit(x_train,y_train)\n",
    "#     #model.  #fit using x_train and y_train\n",
    "#     y_pred = model.predict(x_test)\n",
    "#     return y_pred\n",
    "# # Scikit learn library results\n",
    "# y_pred=SVM(x_train,y_train, x_test)\n",
    "# print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = 'C:\\\\Users\\\\User\\\\Desktop\\\\4th_year_AMLS\\\\zceecyt-AMLSassignment19_20-16053203\\\\notebook\\\\A1'\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import landmarks as l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return l2.extract_features_labels()\n",
    "    \n",
    "def split_data(X, Y):\n",
    "#     split = 4000\n",
    "        \n",
    "#     tr_X = X[:split]\n",
    "#     tr_Y = Y[:split]\n",
    "#     te_X = X[split:]\n",
    "#     te_Y = Y[split:]\n",
    "\n",
    "    X, Y = shuffle(X,Y)\n",
    "    tr_X, te_X, tr_Y, te_Y = train_test_split(X, Y, train_size=0.7)\n",
    "    \n",
    "    return tr_X, tr_Y, te_X, te_Y\n",
    "    \n",
    "    \n",
    "#     for i in [tr_X, tr_Y, te_X, te_Y]:\n",
    "#         print(i.shape)\n",
    "    \n",
    "#     return tr_X, tr_Y, te_X, te_Y\n",
    "    \n",
    "# get_data()\n",
    "\n",
    "\n",
    "# def train_validate_test_split(l2, train_set=0.6, validate_set=0.1, seed=None):\n",
    "#     np.random.seed(seed)\n",
    "#     np.random.seed(0)\n",
    "#     pmt = np.random.permutation(l2.extract_features_labels())\n",
    "#     k = len(l2.extract_features_labels())\n",
    "#     training = int(train_set * k)\n",
    "#     validating = int(validate_set * k) + training\n",
    "#     train = l2.iloc[pmt[:training]]\n",
    "#     validate = l2.iloc[pmt[training:validating]]\n",
    "#     test = l2.iloc[pmt[validating:]]\n",
    "#     return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4798, 68, 2)\n",
      "(4798,)\n"
     ]
    }
   ],
   "source": [
    "X,y = get_data()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\4th_year_AMLS\\zceecyt-AMLSassignment19_20-16053203\\notebook\\A1\n"
     ]
    }
   ],
   "source": [
    "print (os.path.abspath(os.curdir))\n",
    "# sklearn functions implementation\n",
    "def img_SVM(training_images, training_labels, test_images, test_labels):\n",
    "    #classifier = ...\n",
    "    classifier = SVC(kernel = 'rbf')\n",
    "    classifier.fit(training_images, training_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Accuracy:\", accuracy_score(test_labels, pred))\n",
    "\n",
    "    print(pred)\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([y, -(y - 1)]).T\n",
    "\n",
    "tr_X, tr_Y, te_X, te_Y = split_data(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 48 118]\n",
      "  [ 47 128]\n",
      "  [ 47 138]\n",
      "  ...\n",
      "  [ 92 152]\n",
      "  [ 87 153]\n",
      "  [ 82 152]]\n",
      "\n",
      " [[ 42 108]\n",
      "  [ 42 120]\n",
      "  [ 42 132]\n",
      "  ...\n",
      "  [ 96 154]\n",
      "  [ 92 155]\n",
      "  [ 88 155]]\n",
      "\n",
      " [[ 41 117]\n",
      "  [ 42 129]\n",
      "  [ 44 141]\n",
      "  ...\n",
      "  [ 94 157]\n",
      "  [ 90 157]\n",
      "  [ 86 157]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 44 108]\n",
      "  [ 45 120]\n",
      "  [ 47 133]\n",
      "  ...\n",
      "  [ 93 157]\n",
      "  [ 88 158]\n",
      "  [ 83 157]]\n",
      "\n",
      " [[ 26 120]\n",
      "  [ 28 134]\n",
      "  [ 30 146]\n",
      "  ...\n",
      "  [ 97 156]\n",
      "  [ 91 157]\n",
      "  [ 84 157]]\n",
      "\n",
      " [[ 44 105]\n",
      "  [ 45 118]\n",
      "  [ 47 131]\n",
      "  ...\n",
      "  [ 95 158]\n",
      "  [ 90 160]\n",
      "  [ 85 159]]]\n",
      "(3358, 68, 2)\n",
      "[[ 1. -0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " ...\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1. -0.]]\n",
      "(3358, 2)\n"
     ]
    }
   ],
   "source": [
    "print(tr_X)\n",
    "print(tr_X.shape)\n",
    "print(tr_Y)\n",
    "print(tr_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def totuple(a):\n",
    "#     return list(zip(*tr_Y))[0]\n",
    "\n",
    "# # pred=img_SVM(tr_X.reshape((3500, 2500*2)), list(zip(*tr_Y))[0], te_X.reshape((3500, 2500*2)), list(zip(*te_Y))[0])\n",
    "# # pred=img_SVM(tr_X.reshape((len(tr_X), 68*2)), totuple(tr_Y), te_X.reshape((len(te_X), 68*2)), totuple(te_Y))\n",
    "# # pred\n",
    "# pred=img_SVM(\n",
    "#     tr_X.reshape(tr_X.shape[0], tr_X.shape[1]*tr_X.shape[2]),\n",
    "#     totuple(tr_Y), \n",
    "#     te_X.reshape((te_X.shape[0], te_X.shape[1]*te_X.shape[2])), \n",
    "#     totuple(te_Y)\n",
    "# )\n",
    "# # tr_X.shape\n",
    "\n",
    "def reshapeX(X):\n",
    "    return X.reshape((X.shape[0], X.shape[1] * X.shape[2]))\n",
    "\n",
    "def reshapeY(y):\n",
    "    return list(zip(*y))[0]\n",
    "\n",
    "tr_X = reshapeX(tr_X)\n",
    "te_X = reshapeX(te_X)\n",
    "tr_Y = reshapeY(tr_Y)\n",
    "te_Y = reshapeY(te_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3358, 136)\n"
     ]
    }
   ],
   "source": [
    "print(tr_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 0.01 Rbf: 0.5027777777777778\n",
      "0.1 1 Poly 0.5027777777777778\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 0.01 Rbf: 0.5027777777777778\n",
      "0.1 2 Poly 0.8548611111111111\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 0.01 Rbf: 0.5027777777777778\n",
      "0.1 3 Poly 0.90625\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 0.01 Rbf: 0.5027777777777778\n",
      "0.1 4 Poly 0.9173611111111111\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 10 Rbf: 0.5027777777777778\n",
      "0.1 1 Poly 0.5027777777777778\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 10 Rbf: 0.5027777777777778\n",
      "0.1 2 Poly 0.8548611111111111\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 10 Rbf: 0.5027777777777778\n",
      "0.1 3 Poly 0.90625\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 10 Rbf: 0.5027777777777778\n",
      "0.1 4 Poly 0.9173611111111111\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 100 Rbf: 0.5027777777777778\n",
      "0.1 1 Poly 0.5027777777777778\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 100 Rbf: 0.5027777777777778\n",
      "0.1 2 Poly 0.8548611111111111\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 100 Rbf: 0.5027777777777778\n",
      "0.1 3 Poly 0.90625\n",
      "0.1 Linear: 0.9111111111111111\n",
      "0.1 100 Rbf: 0.5027777777777778\n",
      "0.1 4 Poly 0.9173611111111111\n",
      "1 Linear: 0.9069444444444444\n",
      "1 0.01 Rbf: 0.7895833333333333\n",
      "1 1 Poly 0.8159722222222222\n",
      "1 Linear: 0.9069444444444444\n",
      "1 0.01 Rbf: 0.7895833333333333\n",
      "1 2 Poly 0.8965277777777778\n",
      "1 Linear: 0.9069444444444444\n",
      "1 0.01 Rbf: 0.7895833333333333\n",
      "1 3 Poly 0.9173611111111111\n",
      "1 Linear: 0.9069444444444444\n",
      "1 0.01 Rbf: 0.7895833333333333\n",
      "1 4 Poly 0.9180555555555555\n",
      "1 Linear: 0.9069444444444444\n",
      "1 10 Rbf: 0.5027777777777778\n",
      "1 1 Poly 0.8159722222222222\n",
      "1 Linear: 0.9069444444444444\n",
      "1 10 Rbf: 0.5027777777777778\n",
      "1 2 Poly 0.8965277777777778\n",
      "1 Linear: 0.9069444444444444\n",
      "1 10 Rbf: 0.5027777777777778\n",
      "1 3 Poly 0.9173611111111111\n",
      "1 Linear: 0.9069444444444444\n",
      "1 10 Rbf: 0.5027777777777778\n",
      "1 4 Poly 0.9180555555555555\n",
      "1 Linear: 0.9069444444444444\n",
      "1 100 Rbf: 0.5027777777777778\n",
      "1 1 Poly 0.8159722222222222\n",
      "1 Linear: 0.9069444444444444\n",
      "1 100 Rbf: 0.5027777777777778\n",
      "1 2 Poly 0.8965277777777778\n",
      "1 Linear: 0.9069444444444444\n",
      "1 100 Rbf: 0.5027777777777778\n",
      "1 3 Poly 0.9173611111111111\n",
      "1 Linear: 0.9069444444444444\n",
      "1 100 Rbf: 0.5027777777777778\n",
      "1 4 Poly 0.9180555555555555\n"
     ]
    }
   ],
   "source": [
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "#rbf is for gaussian\n",
    "# SVM regularization parameter\n",
    "\n",
    "# C is the element, i.e. 0.1 and 1\n",
    "for C in [0.1,1]:\n",
    "    for gamma in [0.01, 10, 100]:\n",
    "        for degree in [1, 2, 3, 4]:\n",
    "# for i in range(0.1,1,0.1)\n",
    "\n",
    "# for i in range(len(C_loop)): # C is the index, i.e. 0 and 1\n",
    "#     print(i, C_loop[i])\n",
    "            lin_svc = svm.SVC(kernel='linear', C=C).fit(tr_X, tr_Y)\n",
    "            print(C, \"Linear:\", lin_svc.score(te_X, te_Y))\n",
    "\n",
    "            rbf_svc = svm.SVC(kernel='rbf', gamma=gamma, C=C).fit(tr_X, tr_Y)\n",
    "            print( C, gamma, \"Rbf:\", rbf_svc.score(te_X, te_Y))\n",
    "\n",
    "            poly_svc = svm.SVC(kernel='poly', degree=degree, C=C).fit(tr_X, tr_Y)\n",
    "            print( C, degree, \"Poly\", poly_svc.score(te_X, te_Y))\n",
    "            \n",
    "# lin_svc = svm.SVC(kernel='linear', C=C).fit(tr_X, tr_Y)\n",
    "# print(C, \"Linear:\", lin_svc.score(te_X, te_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-18be60bbb6cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n\u001b[0m\u001b[0;32m    136\u001b[0m                     cv=cv, n_jobs=4)\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "\n",
    "\n",
    "title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC(gamma=0.001)\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1130.0568232536316 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
