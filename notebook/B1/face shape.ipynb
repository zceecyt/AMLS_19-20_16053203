{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import adam\n",
    "from keras import models\n",
    "import cv2\n",
    "import dlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time \n",
    "import progressbar\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_shape</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>9995.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>9996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2</td>\n",
       "      <td>9997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>9998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>9999.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     face_shape file_name\n",
       "0             4     0.png\n",
       "1             4     1.png\n",
       "2             3     2.png\n",
       "3             0     3.png\n",
       "4             2     4.png\n",
       "...         ...       ...\n",
       "9995          2  9995.png\n",
       "9996          3  9996.png\n",
       "9997          2  9997.png\n",
       "9998          2  9998.png\n",
       "9999          2  9999.png\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../dataset/cartoon_set/labels.csv', sep = '\\t')\n",
    "df = df.drop(columns = [df.columns[0]]).drop(columns = [df.columns[1]])\n",
    "df['face_shape'] = df['face_shape'].apply(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ('../../dataset/cartoon_set/img')\n",
    "training, testing = train_test_split(df, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Preparation: \n",
      "Found 5625 validated image filenames belonging to 5 classes.\n",
      "\n",
      "Validation Dataset Preparation: \n",
      "Found 1875 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# set up data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    validation_split = 0.25,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True   \n",
    ")\n",
    "\n",
    "# # get batches of training images from the df\n",
    "# train_generator = data_generator.flow_from_dataframe(\n",
    "#         dataframe=train_set,\n",
    "#         x_col=\"file_name\",\n",
    "#         y_col=\"face_shape\",\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=12,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# validate_generator = data_generator.flow_from_dataframe(\n",
    "#         dataframe=train_set,\n",
    "#         x_col=\"file_name\",\n",
    "#         y_col=\"face_shape\",\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=12,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# Get batches of training dataset from the dataframe\n",
    "print(\"Training Dataset Preparation: \")\n",
    "train_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = training, directory = img ,\n",
    "        x_col = \"file_name\", y_col = \"face_shape\",\n",
    "        class_mode = 'categorical', target_size = (178,218),\n",
    "        batch_size = 32, subset = 'training') \n",
    "   \n",
    "# Get batches of validation dataset from the dataframe\n",
    "print(\"\\nValidation Dataset Preparation: \")\n",
    "validation_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = training, directory = img ,\n",
    "        x_col = \"file_name\", y_col = \"face_shape\",\n",
    "        class_mode = 'categorical', target_size = (178,218),\n",
    "        batch_size = 32, subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point \n",
    "my_model= models.Sequential()\n",
    "\n",
    "# Add first convolutional block\n",
    "my_model.add(Conv2D(24, (3, 3), activation='relu', padding='same', \n",
    "                    input_shape=(178,218,3)))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# second block\n",
    "my_model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# third block\n",
    "my_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# fourth block\n",
    "my_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 178, 218, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 89, 109, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 89, 109, 32)       4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 45, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 45, 55, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 23, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 23, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 12, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21504)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 107525    \n",
      "=================================================================\n",
      "Total params: 204,965\n",
      "Trainable params: 204,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# global average pooling\n",
    "#my_model.add(GlobalAveragePooling2D())\n",
    "# fully connected layer\n",
    "#my_model.add(Dense(64, activation='relu'))\n",
    "#my_model.add(BatchNormalization())\n",
    "# make predictions\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Dense(5, activation='softmax'))\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# use early stopping to optimally terminate training through callbacks\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# save best model automatically\n",
    "mc= ModelCheckpoint('/../../dataset/cartoon_set', monitor='val_loss', \n",
    "                    mode='min', verbose=1, save_best_only=True)\n",
    "cb_list=[es,mc]\n",
    "\n",
    "\n",
    "# compile model \n",
    "my_model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "40/40 [==============================] - 52s 1s/step - loss: 1.6098 - accuracy: 0.2078 - val_loss: 1.6085 - val_accuracy: 0.2047\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 52s 1s/step - loss: 1.6095 - accuracy: 0.2047 - val_loss: 1.6099 - val_accuracy: 0.1871\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 51s 1s/step - loss: 1.6087 - accuracy: 0.2102 - val_loss: 1.6036 - val_accuracy: 0.1886\n",
      "Epoch 4/25\n",
      "40/40 [==============================] - 51s 1s/step - loss: 1.5910 - accuracy: 0.2734 - val_loss: 1.5024 - val_accuracy: 0.3648\n",
      "Epoch 5/25\n",
      "40/40 [==============================] - 52s 1s/step - loss: 1.0850 - accuracy: 0.5679 - val_loss: 0.4877 - val_accuracy: 0.8208\n",
      "Epoch 6/25\n",
      "40/40 [==============================] - 54s 1s/step - loss: 0.3769 - accuracy: 0.8594 - val_loss: 0.2748 - val_accuracy: 0.8950\n",
      "Epoch 7/25\n",
      "40/40 [==============================] - 51s 1s/step - loss: 0.2016 - accuracy: 0.9289 - val_loss: 0.1974 - val_accuracy: 0.9727\n",
      "Epoch 8/25\n",
      "40/40 [==============================] - 54s 1s/step - loss: 0.1303 - accuracy: 0.9539 - val_loss: 0.0438 - val_accuracy: 0.9692\n",
      "Epoch 9/25\n",
      "40/40 [==============================] - 53s 1s/step - loss: 0.0938 - accuracy: 0.9686 - val_loss: 0.0323 - val_accuracy: 0.9779\n",
      "Epoch 10/25\n",
      "40/40 [==============================] - 53s 1s/step - loss: 0.0660 - accuracy: 0.9772 - val_loss: 0.1473 - val_accuracy: 0.9812\n",
      "Epoch 11/25\n",
      "40/40 [==============================] - 56s 1s/step - loss: 0.0587 - accuracy: 0.9828 - val_loss: 0.0302 - val_accuracy: 0.9866\n",
      "Epoch 12/25\n",
      "40/40 [==============================] - 57s 1s/step - loss: 0.0432 - accuracy: 0.9891 - val_loss: 0.0051 - val_accuracy: 0.9779\n",
      "Epoch 13/25\n",
      "40/40 [==============================] - 57s 1s/step - loss: 0.0383 - accuracy: 0.9875 - val_loss: 0.0838 - val_accuracy: 0.9859\n",
      "Epoch 14/25\n",
      "40/40 [==============================] - 56s 1s/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.0586 - val_accuracy: 0.9929\n",
      "Epoch 15/25\n",
      "40/40 [==============================] - 1506s 38s/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 0.0646 - val_accuracy: 0.9905\n",
      "Epoch 16/25\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0243 - accuracy: 0.9945 - val_loss: 0.0013 - val_accuracy: 0.9906\n",
      "Epoch 17/25\n",
      " 1/40 [..............................] - ETA: 1:04 - loss: 0.0321 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\virtualcy\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (1.796455). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 57s 1s/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.0051 - val_accuracy: 0.9945\n",
      "Epoch 18/25\n",
      "40/40 [==============================] - 55s 1s/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.0012 - val_accuracy: 0.9905\n",
      "Epoch 19/25\n",
      "40/40 [==============================] - 55s 1s/step - loss: 0.0202 - accuracy: 0.9922 - val_loss: 0.0107 - val_accuracy: 0.9906\n",
      "Epoch 20/25\n",
      "40/40 [==============================] - 57s 1s/step - loss: 0.0235 - accuracy: 0.9891 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 21/25\n",
      "40/40 [==============================] - 54s 1s/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.0444 - val_accuracy: 0.9953\n",
      "Epoch 22/25\n",
      "40/40 [==============================] - 55s 1s/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0310 - val_accuracy: 0.9937\n",
      "Epoch 23/25\n",
      "40/40 [==============================] - 57s 1s/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0081 - val_accuracy: 0.9945\n",
      "Epoch 24/25\n",
      "40/40 [==============================] - 53s 1s/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.1566 - val_accuracy: 0.9905\n",
      "Epoch 25/25\n",
      "40/40 [==============================] - 55s 1s/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0034 - val_accuracy: 0.9945\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit_generator(\n",
    "                                train_generator,\n",
    "                                epochs=25,\n",
    "                                steps_per_epoch=40,\n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=40\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-98-a8e496adabfe>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-98-a8e496adabfe>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    target_size=(178, 218),\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = training, directory = img,\n",
    "        x_col = \"file_name\", y_col = \"face_shape\"\n",
    "        target_size=(178, 218),\n",
    "        batch_size=12,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-f16fb80b85a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# determine the maximum activation value for each sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredicted_class_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=saved_model.predict_generator(test_generator, verbose=1, steps=1000)\n",
    "# determine the maximum activation value for each sample\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "# label each predicted value to correct gender\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# format file names to simply male or female\n",
    "filenames=test_generator.filenames\n",
    "filenz=[0]\n",
    "for i in range(0,len(filenames)):\n",
    "    filenz.append(filenames[i].split('\\\\')[0])\n",
    "filenz=filenz[1:]\n",
    "\n",
    "# determine the test set accuracy\n",
    "match=[]\n",
    "for i in range(0,len(filenames)):\n",
    "    match.append(filenz[i]==predictions[i])\n",
    "match.count(True)/1000\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
