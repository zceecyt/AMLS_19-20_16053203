{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import adam\n",
    "from keras import models\n",
    "import cv2\n",
    "import dlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time \n",
    "import progressbar\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_shape</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>9995.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>9996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2</td>\n",
       "      <td>9997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>9998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>9999.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     face_shape file_name\n",
       "0             4     0.png\n",
       "1             4     1.png\n",
       "2             3     2.png\n",
       "3             0     3.png\n",
       "4             2     4.png\n",
       "...         ...       ...\n",
       "9995          2  9995.png\n",
       "9996          3  9996.png\n",
       "9997          2  9997.png\n",
       "9998          2  9998.png\n",
       "9999          2  9999.png\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../dataset/cartoon_set/labels.csv', sep = '\\t')\n",
    "df = df.drop(columns = [df.columns[0]]).drop(columns = [df.columns[1]])\n",
    "df['face_shape'] = df['face_shape'].apply(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     face_shape file_name\n",
      "5944          2  5944.png\n",
      "1933          1  1933.png\n",
      "8701          0  8701.png\n",
      "7079          3  7079.png\n",
      "7137          1  7137.png\n",
      "...         ...       ...\n",
      "8140          4  8140.png\n",
      "8997          3  8997.png\n",
      "6540          1  6540.png\n",
      "4348          3  4348.png\n",
      "9114          0  9114.png\n",
      "\n",
      "[6000 rows x 2 columns]      face_shape file_name\n",
      "3850          1  3850.png\n",
      "5130          0  5130.png\n",
      "8437          0  8437.png\n",
      "1361          1  1361.png\n",
      "4551          0  4551.png\n",
      "...         ...       ...\n",
      "3808          4  3808.png\n",
      "2372          0  2372.png\n",
      "8200          2  8200.png\n",
      "653           2   653.png\n",
      "9042          0  9042.png\n",
      "\n",
      "[2000 rows x 2 columns]      face_shape file_name\n",
      "4181          2  4181.png\n",
      "9159          4  9159.png\n",
      "6974          4  6974.png\n",
      "3893          3  3893.png\n",
      "6016          3  6016.png\n",
      "...         ...       ...\n",
      "9409          2  9409.png\n",
      "4499          3  4499.png\n",
      "3825          0  3825.png\n",
      "3973          0  3973.png\n",
      "142           1   142.png\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "img = ('../../dataset/cartoon_set/img')\n",
    "# training, testing = train_test_split(df, random_state=0)\n",
    "training, validating, testing = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))]) #splitting at n-array\n",
    "print(training, validating, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Preparation: \n",
      "Found 6000 validated image filenames belonging to 5 classes.\n",
      "\n",
      "Validation Dataset Preparation: \n",
      "Found 2000 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# set up data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "#     validation_split = 0.25,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True   \n",
    ")\n",
    "\n",
    "# # get batches of training images from the df\n",
    "# train_generator = data_generator.flow_from_dataframe(\n",
    "#         dataframe=train_set,\n",
    "#         x_col=\"file_name\",\n",
    "#         y_col=\"face_shape\",\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=12,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# validate_generator = data_generator.flow_from_dataframe(\n",
    "#         dataframe=train_set,\n",
    "#         x_col=\"file_name\",\n",
    "#         y_col=\"face_shape\",\n",
    "#         target_size=(178, 218),\n",
    "#         batch_size=12,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# Get batches of training dataset from the dataframe\n",
    "print(\"Training Dataset Preparation: \")\n",
    "train_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = training, directory = img ,\n",
    "        x_col = \"file_name\", y_col = \"face_shape\",\n",
    "        class_mode = 'categorical', target_size = (30,30),\n",
    "        batch_size = 32, subset = 'training') \n",
    "   \n",
    "# Get batches of validation dataset from the dataframe\n",
    "print(\"\\nValidation Dataset Preparation: \")\n",
    "validation_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = validating, directory = img ,\n",
    "        x_col = \"file_name\", y_col = \"face_shape\",\n",
    "        class_mode = 'categorical', target_size = (30,30),\n",
    "        batch_size = 32, subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 15, 15, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 100,005\n",
      "Trainable params: 100,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# starting point \n",
    "my_model= models.Sequential()\n",
    "\n",
    "# Add first convolutional block\n",
    "my_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', \n",
    "                    input_shape=(30,30,3))) #height, width, depth\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# second block\n",
    "my_model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) #Convolution: filters, kernel_size that specifies the height and width of the 2D convolution window, p padding layers so dimensions of input = output\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# third block\n",
    "my_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# fourth block\n",
    "my_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "my_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "# global average pooling\n",
    "#my_model.add(GlobalAveragePooling2D())\n",
    "# fully connected layer\n",
    "#my_model.add(Dense(64, activation='relu'))\n",
    "#my_model.add(BatchNormalization())\n",
    "# make predictions\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Dense(5, activation='softmax'))\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use early stopping to optimally terminate training through callbacks\n",
    "\n",
    "# es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# # save best model automatically\n",
    "# mc= ModelCheckpoint('/../../dataset/cartoon_set', monitor='val_loss', \n",
    "#                     mode='min', verbose=1, save_best_only=True)\n",
    "# cb_list=[es,mc]\n",
    "\n",
    "\n",
    "# compile model \n",
    "my_model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "187/187 [==============================] - 40s 216ms/step - loss: 1.5229 - accuracy: 0.2656 - val_loss: 1.2223 - val_accuracy: 0.3765\n",
      "Epoch 2/25\n",
      "187/187 [==============================] - 28s 152ms/step - loss: 1.1513 - accuracy: 0.4358 - val_loss: 1.1478 - val_accuracy: 0.5412\n",
      "Epoch 3/25\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 0.9639 - accuracy: 0.5736 - val_loss: 0.7487 - val_accuracy: 0.6956\n",
      "Epoch 4/25\n",
      "187/187 [==============================] - 29s 154ms/step - loss: 0.6446 - accuracy: 0.7348 - val_loss: 0.6485 - val_accuracy: 0.6911\n",
      "Epoch 5/25\n",
      "187/187 [==============================] - 30s 160ms/step - loss: 0.5227 - accuracy: 0.7864 - val_loss: 0.4566 - val_accuracy: 0.7795\n",
      "Epoch 6/25\n",
      "187/187 [==============================] - 30s 163ms/step - loss: 0.4335 - accuracy: 0.8266 - val_loss: 0.2843 - val_accuracy: 0.8308\n",
      "Epoch 7/25\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 0.3904 - accuracy: 0.8430 - val_loss: 0.4346 - val_accuracy: 0.8069\n",
      "Epoch 8/25\n",
      "187/187 [==============================] - 29s 155ms/step - loss: 0.3516 - accuracy: 0.8656 - val_loss: 0.1019 - val_accuracy: 0.8460\n",
      "Epoch 9/25\n",
      "187/187 [==============================] - 27s 145ms/step - loss: 0.3141 - accuracy: 0.8743 - val_loss: 0.3670 - val_accuracy: 0.8506\n",
      "Epoch 10/25\n",
      "187/187 [==============================] - 28s 150ms/step - loss: 0.2706 - accuracy: 0.8970 - val_loss: 0.2255 - val_accuracy: 0.8826\n",
      "Epoch 11/25\n",
      "187/187 [==============================] - 28s 151ms/step - loss: 0.2623 - accuracy: 0.9023 - val_loss: 0.4608 - val_accuracy: 0.8796\n",
      "Epoch 12/25\n",
      "187/187 [==============================] - 30s 160ms/step - loss: 0.2482 - accuracy: 0.9085 - val_loss: 0.4430 - val_accuracy: 0.8892\n",
      "Epoch 13/25\n",
      "187/187 [==============================] - 34s 179ms/step - loss: 0.2242 - accuracy: 0.9161 - val_loss: 0.1460 - val_accuracy: 0.9014\n",
      "Epoch 14/25\n",
      "187/187 [==============================] - 35s 188ms/step - loss: 0.2056 - accuracy: 0.9236 - val_loss: 0.4104 - val_accuracy: 0.9070\n",
      "Epoch 15/25\n",
      "187/187 [==============================] - 34s 184ms/step - loss: 0.1757 - accuracy: 0.9362 - val_loss: 0.1461 - val_accuracy: 0.9029\n",
      "Epoch 16/25\n",
      "187/187 [==============================] - 42s 224ms/step - loss: 0.1779 - accuracy: 0.9333 - val_loss: 0.2126 - val_accuracy: 0.9121\n",
      "Epoch 17/25\n",
      "187/187 [==============================] - 34s 180ms/step - loss: 0.1634 - accuracy: 0.9382 - val_loss: 0.2324 - val_accuracy: 0.9151\n",
      "Epoch 18/25\n",
      "187/187 [==============================] - 34s 184ms/step - loss: 0.1472 - accuracy: 0.9420 - val_loss: 0.2314 - val_accuracy: 0.9243\n",
      "Epoch 19/25\n",
      "187/187 [==============================] - 34s 183ms/step - loss: 0.1401 - accuracy: 0.9487 - val_loss: 0.2543 - val_accuracy: 0.9197\n",
      "Epoch 20/25\n",
      "187/187 [==============================] - 34s 182ms/step - loss: 0.1441 - accuracy: 0.9481 - val_loss: 0.3985 - val_accuracy: 0.9035\n",
      "Epoch 21/25\n",
      "187/187 [==============================] - 34s 180ms/step - loss: 0.1318 - accuracy: 0.9512 - val_loss: 0.2085 - val_accuracy: 0.9172\n",
      "Epoch 22/25\n",
      "187/187 [==============================] - 34s 183ms/step - loss: 0.1265 - accuracy: 0.9509 - val_loss: 0.1859 - val_accuracy: 0.9319\n",
      "Epoch 23/25\n",
      "187/187 [==============================] - 34s 183ms/step - loss: 0.1172 - accuracy: 0.9554 - val_loss: 0.2987 - val_accuracy: 0.9192\n",
      "Epoch 24/25\n",
      "187/187 [==============================] - 34s 183ms/step - loss: 0.0997 - accuracy: 0.9660 - val_loss: 0.0313 - val_accuracy: 0.9314\n",
      "Epoch 25/25\n",
      "187/187 [==============================] - 34s 182ms/step - loss: 0.1239 - accuracy: 0.9529 - val_loss: 0.1606 - val_accuracy: 0.9212\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "history = my_model.fit_generator(\n",
    "                                train_generator,\n",
    "                                epochs=25,\n",
    "                                steps_per_epoch=train_generator.samples // batch_size,\n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=validation_generator.samples // batch_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = data_generator.flow_from_dataframe(\n",
    "        dataframe = testing, directory = img,\n",
    "        x_col = \"file_name\", y_col = \"face_shape\",\n",
    "        batch_size=32,\n",
    "        class_mode='categorical', target_size=(30, 30),\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saved_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-03317fba676e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# determine the maximum activation value for each sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredicted_class_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'saved_model' is not defined"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=saved_model.predict_generator(test_generator, verbose=1, steps=1000)\n",
    "# determine the maximum activation value for each sample\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "# label each predicted value to correct gender\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# format file names to simply male or female\n",
    "filenames=test_generator.filenames\n",
    "filenz=[0]\n",
    "for i in range(0,len(filenames)):\n",
    "    filenz.append(filenames[i].split('\\\\')[0])\n",
    "filenz=filenz[1:]\n",
    "\n",
    "# determine the test set accuracy\n",
    "match=[]\n",
    "for i in range(0,len(filenames)):\n",
    "    match.append(filenz[i]==predictions[i])\n",
    "match.count(True)/1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10919.487528562546 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
